---
title: "SMDE LAB Assignment 1"
author: "Miguel Alvarez"
date: "23 de octubre de 2018"
output:
  html_document: default
  pdf_document: default
---

http://www.simplehtmlguide.com/cheatsheet.php


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Q1: Random Number Generator
OBJECTIVE  
The objective of the first question is to compare the random number generator included in the program R with a tested RNG to ensure the randomness of the first one through the Chi-Square test of a collection of 200 values generated by each of them.

PROCEDURE  
First, we must generate a collection of values with one of the approved algorithms. For this, we chose Blum Blum Shub algorithm with parameters p = 87566873, q = 15485143 and seed = 193945. 

In Rstudio, we generate another collection of values though the function "runif". We arrange our data in 0.1 brackets between 0 and 1 to count frequency of events. Then, we can run the Chi - Square test obtaining a P-value of 0.64.

RESULTS  
Comparing the P-value to a significance level of 0.05, we se that P = 0.64 > 0.05 is fairly greater. Despite being generated by a deterministic algorithm, it is proven that both algorithms generate a seemingly random collection of values. Accepting that Blum Blum Shub algorithm has passed all randomness tests, we can We can accept then the null hypothesis, so we can accept R's RNG.

Is the sample generated by the RNG similar to the one generated on R?
Looking at table 1, we can see that indeed both samples are similar at first glimps. Test shows that they are independent.

Are you really comparing the quality of the RNG or the RVG?
A random number generator (often abbreviated as RNG) is a computational or physical device designed to generate a sequence of numbers or symbols that lack any pattern, i.e. appear random, while a random value generator is a specific probability distribution that we can obtain from a Random Number Generator. 
According to this deffinitions, the test was performed to a random value generator as we asked specifically for a normal distribution.

Q1 CODE
```{r Q1RNG}

BBS = read.table("rngbbs.txt")

v1 = runif(200, min = 0, max = 1)
v2 = BBS[,1]


summary(v1)
summary(v2)

table_v1 = data.frame(x1 = v1)
table_v1_cat = transform(table_v1, cat = ifelse(x1 < 0.1,"0.1",
                                               ifelse(x1 < 0.2,"0.2",
                                                     ifelse(x1 < 0.3,"0.3",
                                                            ifelse(x1 < 0.4,"0.4",
                                                                   ifelse(x1 < 0.5,"0.5",
                                                                          ifelse(x1 < 0.6,"0.6",
                                                                                 ifelse(x1 < 0.7,"0.7",
                                                                                        ifelse(x1 < 0.8,"0.8",
                                                                                               ifelse(x1 < 0.9,"0.9",
                                                                                                      ifelse(x1 < 1.0,"1.0")))))))))))

table_freq_v1 = as.data.frame(with(table_v1_cat, table(cat)))

table_v2 = data.frame(x1 = v2)
table_v2_cat = transform(table_v2, cat = ifelse(x1 < 0.1,"0.1",
                                              ifelse(x1 < 0.2,"0.2",
                                                     ifelse(x1 < 0.3,"0.3",
                                                            ifelse(x1 < 0.4,"0.4",
                                                                   ifelse(x1 < 0.5,"0.5",
                                                                          ifelse(x1 < 0.6,"0.6",
                                                                                 ifelse(x1 < 0.7,"0.7",
                                                                                        ifelse(x1 < 0.8,"0.8",
                                                                                               ifelse(x1 < 0.9,"0.9",
                                                                                                      ifelse(x1 < 1.0,"1.0")))))))))))


table_freq_v2 = as.data.frame(with(table_v2_cat, table(cat)))
testDataFreq <- data.frame(table_freq_v1$Freq)
testDataFreq$Freq2 <- table_freq_v2$Freq

test=chisq.test(testDataFreq, correct=FALSE)
show(test)
```

##################################################################################################################################
##################################################################################################################################
##################################################################################################################################
##################################################################################################################################

Q2: ANOVA  
  
OBJECTIVE  
The objective of question 2 is to familiarize with ANOVA and ANOVA assumptions, first with 3 random generated populations and later with an example from the package "FactoMineR".

PROCEDURE  
ANOVA test is used for comparing means in a situation where there are more than two groups. To take such test, first we must check ANOVA assumptions which are:

  - The observations are obtained independently and randomly from the population defined by the factor levels, Durbin-Watson test.
  - The data of each factor level are normally distributed, Shapiro - Wilkins test.
  - These normal populations have a common variance, Breusch Pagan test.

We will check if null hypothesis: "the means of the different groups are the same" with an alternative hypothesis: "at least one sample mean is not equal to the others".

RESULTS  
ANOVA and hypothesis interpretation for each test.

ANOVA: P > alpha ->means are equal. 
ANOVA: P < alpha -> means are not equal.
Durbin-Watson: P > alpha -> populations are not autocorrelated. 
Durbin-Watson: P < alpha -> poulations are autocorrelated. ANOVA test is not significant.
Shapiro-Wilkins: P > alpha -> populaions follow normal distribution. 
Shapiro-Wilkins: P < alpha -> populations do not follow normal distribution. Anova test is not significant.
Breusch-Pagan: P > alpha ->  homoskedasticity (variances are equal).
Breusch-Pagan: P < alpha -> heteroskedasticity(variances are not equal). ANOVA test is not significant.

 Considering alpha = 0.05



  Example  
ANOVA: P <2e-16 < alpha -> means are not equal.  
Durbin-Watson: p-value = 0.06936 > alpha -> populations are not autocorrelated.  
Shapiro-Wilkins: p-value = 0.618 > alpha -> populaions follow normal distribution.   
Breusch-Pagan: p-value = 0.4796 > alpha ->  variances are equal.  

  100m Race    
ANOVA: P = 0.00218 < alpha -> means are not equal.  
Durbin-Watson: p-value = 0.008235 < alpha -> poulations are autocorrelated. ANOVA test is not significant.  
Shapiro-Wilkins: p-value = 0.5023 > alpha -> populaions follow normal distribution.   
Breusch-Pagan: p-value = 0.8401 > alpha ->  variances are equal.  

  Long Jump  
ANOVA: P = 0.868 > alpha ->means are equal, but test is not significant.  
Durbin-Watson: p-value = 0.02544 < alpha -> poulations are autocorrelated. ANOVA test is not significant.  
Shapiro-Wilkins: p-value = 0.9437 > alpha -> populaions follow normal distribution.   
Breusch-Pagan: p-value = 0.2621 > alpha ->  variances are equal.  

  Shotput  
ANOVA: P = 0.092 > alpha -> means are equal, although the P value is quite small and test is not significant.  
Durbin-Watson: p-value = 0.04577 < alpha -> poulations are autocorrelated. ANOVA test is not significant.  
Shapiro-Wilkins: p-value = 0.4175 > alpha -> populaions follow normal distribution.   
Breusch-Pagan: p-value = 0.2608 > alpha ->  variances are equal.  

  High Jump  
ANOVA: P = 0.967 > alpha -> means are equal,  but test is not significant.  
Durbin-Watson: p-value = 0.8665 > alpha -> populations are not autocorrelated.  
Shapiro-Wilkins:  p-value = 0.02428 < alpha -> populations do not follow normal distribution. Anova test is not significant.  
Breusch-Pagan: p-value = 0.9212 > alpha ->  variances are equal.  

  400m Race  
ANOVA: P = 0.96 > alpha -> means are equal but test is not significant.  
Durbin-Watson: p-value = 0.03032 < alpha -> poulations are autocorrelated.  ANOVA test is not significant.  
Shapiro-Wilkins: p-value = 0.1206 > alpha -> populaions follow normal distribution.   
Breusch-Pagan: p-value = 0.3051 > alpha ->  variances are equal.  

  110m Hurdle Race  
ANOVA: P = 0.304 > alpha -> means are equal but test is not significant.  
Durbin-Watson: p-value = 0.07622 > alpha -> populations are not autocorrelated.  
Shapiro-Wilkins: p-value = 0.02009 < alpha -> populations do not follow normal distribution. Anova test is not significant.  
Breusch-Pagan: p-value = 0.2872 > alpha ->  variances are equal.  

  Pole Vault  
ANOVA: P = 0.312 > alpha -> means are equal.  
Durbin-Watson: p-value = 0.8782 > alpha -> populations are not autocorrelated.  
Shapiro-Wilkins: p-value = 0.6299 > alpha -> populaions follow normal distribution.   
Breusch-Pagan: p-value = 0.476 > alpha ->  variances are equal.  

  Javeline  
ANOVA: P = 0.223 > alpha -> means are equal.  
Durbin-Watson: p-value = 0.8442 > alpha -> populations are not autocorrelated.  
Shapiro-Wilkins: p-value = 0.4852 > alpha -> populaions follow normal distribution.   
Breusch-Pagan: p-value = 0.521 > alpha ->  variances are equal.  

  1500m Race  
ANOVA: P = 0.24 > alpha -> means are equal but test is not significan.  
Durbin-Watson: p-value = 0.3011 > alpha -> populations are not autocorrelated.  
Shapiro-Wilkins: p-value = 0.02741 < alpha -> populations do not follow normal distribution. Anova test is not significant.  
Breusch-Pagan: p-value = 0.8624 > alpha ->  variances are equal.  



Q2 CODE  
```{r AnovaModel.1}

library(RcmdrMisc)

Norm_v1=rnorm(200, mean=0, sd=1)
Norm_v2=rnorm(200, mean=10, sd=1)
Norm_v3=rnorm(200, mean=0, sd=1)

Norm_v1n=data.frame(x1=Norm_v1, x2="v1")
Norm_v2n=data.frame(x1=Norm_v2, x2="v2")
Norm_v3n=data.frame(x1=Norm_v3, x2="v3")
data=mergeRows(Norm_v1n, Norm_v2n, common.only=FALSE)
data=mergeRows(as.data.frame(data), Norm_v3n, common.only=FALSE)

AnovaModel.1 <- aov(x1 ~ x2, data=data)
summary(AnovaModel.1)
Boxplot(x1~x2, data=data, id.method="y")
```

Testing ANOVA assumptions.
```{r AnovaModel.1 test}
library(lmtest)


#The observations within each sample must be independent.
#Durbin Watson 
dwtest(AnovaModel.1, alternative ="two.sided")
#The populations from which the samples are selected must be normal.
#Shapiro test
shapiro.test(residuals(AnovaModel.1))
#The populations from which the samples are selected must have equal variances (homogeneity of variance)
#Breusch Pagan test
lmtest::bptest(AnovaModel.1)
```
Testing FactoMineR's "Decathlon"
```{R ANOVA_Decathlon}

data(decathlon, package="FactoMineR")
library(RcmdrMisc)
library(lmtest)
```

```{R 100m RACE}
race100m = data.frame(x1=decathlon[,1],x2=decathlon[,13])
anova100m <- aov(x1 ~ x2, data = race100m)
summary(anova100m)
Boxplot(x1~x2, data=race100m, id.method="y", main="100m Race")
dwtest(anova100m, alternative ="two.sided")
shapiro.test(residuals(anova100m))
lmtest::bptest(anova100m)
```

```{R LONG JUMP}
longjump = data.frame(x1=decathlon[,2],x2=decathlon[,13])
anovalongjump <- aov(x1 ~ x2, data = longjump)
summary(anovalongjump)
Boxplot(x1~x2, data=longjump, id.method="y", main="Long Jump")
dwtest(anovalongjump, alternative ="two.sided")
shapiro.test(residuals(anovalongjump))
lmtest::bptest(anovalongjump)
```

```{R SHOT PUT}
shotput = data.frame(x1=decathlon[,3],x2=decathlon[,13])
anovashotput <- aov(x1 ~ x2, data = shotput)
summary(anovashotput)
Boxplot(x1~x2, data=shotput, id.method="y", main ="Shot Put")
dwtest(anovashotput, alternative ="two.sided")
shapiro.test(residuals(anovashotput))
lmtest::bptest(anovashotput)
```

```{R HIGH JUMP}
highjump = data.frame(x1=decathlon[,4],x2=decathlon[,13])
anovahighjump <- aov(x1 ~ x2, data = highjump)
summary(anovahighjump)
Boxplot(x1~x2, data=highjump, id.method="y",main="High Jump")
dwtest(anovahighjump, alternative ="two.sided")
shapiro.test(residuals(anovahighjump))
lmtest::bptest(anovahighjump)
```

```{R 400M RACE}
race400m = data.frame(x1=decathlon[,5],x2=decathlon[,13])
anova400m <- aov(x1 ~ x2, data = race400m)
summary(anova400m)
Boxplot(x1~x2, data=race400m, id.method="y",main="400m Race")
dwtest(anova400m, alternative ="two.sided")
shapiro.test(residuals(anova400m))
lmtest::bptest(anova400m)
```

```{R 110M HURDLE RACE}
race110mhurdle = data.frame(x1=decathlon[,6],x2=decathlon[,13])
anova110mhurdle <- aov(x1 ~ x2, data = race110mhurdle)
summary(anova110mhurdle)
Boxplot(x1~x2, data=race110mhurdle, id.method="y", main = "110m Hurdle Race")
dwtest(anova110mhurdle, alternative ="two.sided")
shapiro.test(residuals(anova110mhurdle))
lmtest::bptest(anova110mhurdle)
```

```{R DISCUS}
discus = data.frame(x1=decathlon[,7],x2=decathlon[,13])
anovadiscus <- aov(x1 ~ x2, data = discus)
summary(anovadiscus)
Boxplot(x1~x2, data=discus, id.method="y",main="Discus")
dwtest(anovadiscus, alternative ="two.sided")
shapiro.test(residuals(anovadiscus))
lmtest::bptest(anovadiscus)
```

```{R POLE VAULT}
polevault = data.frame(x1=decathlon[,8],x2=decathlon[,13])
anovapolevault <- aov(x1 ~ x2, data = polevault)
summary(anovapolevault)
Boxplot(x1~x2, data=polevault, id.method="y",main="Pole Vault") 
dwtest(anovapolevault, alternative ="two.sided")
shapiro.test(residuals(anovapolevault))
lmtest::bptest(anovapolevault)
```

```{R JAVELINE}
javeline = data.frame(x1=decathlon[,9],x2=decathlon[,13])
anovajaveline <- aov(x1 ~ x2, data = javeline)
summary(anovajaveline)
Boxplot(x1~x2, data=javeline, id.method="y", main= "Javeline")
dwtest(anovajaveline, alternative ="two.sided")
shapiro.test(residuals(anovajaveline))
lmtest::bptest(anovajaveline)
```

```{R 1500M RACE}
race1500m = data.frame(x1=decathlon[,10],x2=decathlon[,13])
anova1500m <- aov(x1 ~ x2, data = race1500m)
summary(anova1500m)
Boxplot(x1~x2, data=race1500m, id.method="y", main="1500m Race")
dwtest(anova1500m, alternative ="two.sided")
shapiro.test(residuals(anova1500m))
lmtest::bptest(anova1500m)
```



##################################################################################################################################
##################################################################################################################################
##################################################################################################################################
##################################################################################################################################

Q3: LINEAR REGRESSION MODEL  

OBJECTIVE  
To create a linear expression that best predicts the behaviour of athletes in 1500m race.

PROCEDURE  
Test different expressions and test the assumptions for each of them. Once an expression has been tested and selected, it will be used to predict the result for athletes according to the distinction between confidence intervals, prediction intervals and tolerance intervals.

We used the results in decastar and we will test our predictions with olympic games results.

RESULTS  
  Is this model accurate?
Taking into account the data available in decahtlon dataset, we have made 9 linear models, one for each competition besides 1500m.
We have tested the assumptions which are:

  - The observations are obtained independently and randomly from the population defined by the factor levels, Durbin-Watson test.  
  - The data of each factor level are normally distributed, Shapiro - Wilkins test.  
  - These normal populations have a common variance, Breusch Pagan test.  

Testing our p-value for each linear regression model, we would consider it significant in case that p < 0.05.
  
100m p-value:               0.02495  
long jump p-value:          0.348  
shot put p-value:           0.3158  
highjump p-value:           0.655  
400m p-value:               0.8981  
110m hurdle p-value:        0.8157  
discus p-value:             0.2341  
pole vault p-value:         0.263  
javeline p-value:           0.7674  

combination of all:
Coefficients:
                Estimate Std. Error t value Pr(>|t|)
(Intercept)    674.03810  699.25720   0.964    0.406  
race100m       -59.13625   35.63755  -1.659    0.196  
longjump        -2.95190   18.51848  -0.159    0.883  
shotput          9.04635   16.47967   0.549    0.621  
highjump       -41.60761   89.37385  -0.466    0.673  
race400m         3.85366    8.83489   0.436    0.692  
race11omhurdle   8.61486   23.85722   0.361    0.742  
discus          -0.08491    1.87865  -0.045    0.967  
polevault       -0.28224   39.90849  -0.007    0.995  
javeline        -1.19931    1.26945  -0.945    0.414  

Residual standard error: 12 on 3 degrees of freedom  
Multiple R-squared:  0.7596,	Adjusted R-squared:  0.03855   
F-statistic: 1.053 on 9 and 3 DF,  p-value: 0.543  


The chosen model would be the combination ofall sport events, because is the only model that has a significant P-value (P-value = 0.543 > alpha). Considering alpha = 0.05.

Durbin-Watson: p-value = 0.6357 > alpha -> populations are not autocorrelated.  
Shapiro-Wilkins: p-value = 0.2301 > alpha -> populations follow normal distribution.  
Breusch-Pagan: p-value = 0.2632 > alpha ->  variances are equal.  


Our linear model expression is:  
  t1500m = 674.03810 - 59.13625 x race100m - 2.95190 x longjump + 9.04635 x shotput - 41.60761 x highjump + 3.85366 x race400m + 8.61486 x race110mhurdle - 0.08491 x discus - 0.28224 x polevault - 1.19931 x javeline  


PREDICTIONS

          PREDICTION            CONFIDENCE              ACTUALVALUE     Prediction Fitting      Confidence Fitting
____________________________________________________________________________________________________________________          
Sebrle    |[216.727, 355.9441]   [228.1413, 344.5298]    280.01          T                       T  
Clay      |[245.7087, 368.8325]  [258.9893, 355.5519]    282             T                       T  
Karpov    [161.9203, 469.3747]  [166.7406, 464.5544]    278.11          T                       T  
Macey     [188.6006, 410.4483]  [195.3836, 403.6653]    265.42          T                       T  
Warners   [234.9655, 377.4666]  [246.0674, 366.3647]    278.05          T                       T  
Zsivoczky [214.708, 377.1784]   [224.2468, 367.6397]    269.54          T                       T  
Hernu     [237.8147, 338.7481]  [255.295, 321.2679]     264.35          T                       T  
Nool      [246.983, 354.7497]   [262.858, 338.8747]     276.33          T                       T    
Bernard   [219.4953, 391.5941]  [228.4362, 382.6532]    276.31          T                       T    
Schwarzl  [227.8704, 353.2607]  [240.8474, 340.2838]    273.56          T                       T  

We can see our prediction fits in both intervals but also we can see that both intervals are so wide that they do not provide a very useful information.

Prediction intervals must account for both the uncertainty in knowing the value of the population mean, plus data scatter. So a prediction interval is always wider than a confidence interval.

  What did you expect?
I would expect smaller intervals in the prediction. I do not see any significant information coming from the prediction of our regression model. In my opinion, this is due partly due to the size of the data set. Maybe, ranking or punctuation variables should be included although the original idea is to use only sport event results to predict 1500m result as ranking and punctuation are not independnt variables.


Q3 CODE

```{R LRM100m}
decastar=subset(decathlon, Competition=="Decastar")
olympic=subset(decathlon, Competition=="OlympicG")

colnames(decastar)=c("race100m", "longjump", "shotput", "highjump", "race400m", "race110mhurdle", "discus", "polevault","javeline","race1500m","rank", "points","competition")
colnames(olympic)=c("race100m", "longjump", "shotput", "highjump", "race400m", "race110mhurdle", "discus", "polevault","javeline","race1500m","rank", "points","competition")


linearModrace100m <- lm(race1500m ~ race100m, data=decastar)
linearModlongjump <- lm(race1500m ~ longjump, data=decastar)
linearModshotput <- lm(race1500m ~ shotput, data=decastar)
linearModhighjump <- lm(race1500m ~ highjump, data=decastar)
linearModrace400m <- lm(race1500m ~ race400m, data=decastar)
linearModrace110mhurdle <- lm(race1500m ~ race110mhurdle, data=decastar)
linearModdiscus <- lm(race1500m ~ discus, data=decastar)
linearModpolevault <- lm(race1500m ~ polevault, data=decastar)
linearModjaveline <- lm(race1500m ~ javeline, data=decastar)

summary(linearModrace100m)
summary(linearModlongjump)
summary(linearModshotput)
summary(linearModhighjump)
summary(linearModrace400m)
summary(linearModrace110mhurdle)
summary(linearModdiscus)
summary(linearModpolevault)
summary(linearModjaveline)

linearModcombination <- 
  lm(race1500m~
       race100m+longjump+shotput+highjump+race400m+race110mhurdle+discus+polevault+javeline,
   data=decastar)
summary(linearModcombination)

dwtest(linearModcombination, alternative ="two.sided") #Durbin Watson
shapiro.test(residuals(linearModcombination))#Shapiro test
lmtest::bptest(linearModcombination)#Breusch Pagan test
```

```{R prediction}
library(tolerance)

olympic


olympic["Sebrle",]
Sebrle <- data.frame(olympic["Sebrle",1],olympic["Sebrle",2],olympic["Sebrle",3],olympic["Sebrle",4],olympic["Sebrle",5],olympic["Sebrle",6],olympic["Sebrle",7],olympic["Sebrle",8],olympic["Sebrle",9])
colnames(Sebrle)=c("race100m", "longjump", "shotput", "highjump", "race400m", "race110mhurdle", "discus", "polevault","javeline")
SebrleP <- predict(linearModcombination, newdata=Sebrle, interval="prediction")
SebrleC <- predict(linearModcombination, newdata=Sebrle, interval="confidence")

olympic["Clay",]
Clay <- data.frame(olympic["Clay",1],olympic["Clay",2],olympic["Clay",3],olympic["Clay",4],olympic["Clay",5],olympic["Clay",6],olympic["Clay",7],olympic["Clay",8],olympic["Clay",9])
colnames(Clay)=c("race100m", "longjump", "shotput", "highjump", "race400m", "race110mhurdle", "discus", "polevault","javeline")
ClayP <- predict(linearModcombination, newdata=Clay, interval="prediction")
ClayC <- predict(linearModcombination, newdata=Clay, interval="confidence")

olympic["Karpov",]
Karpov <- data.frame(olympic["Karpov",1],olympic["Karpov",2],olympic["Karpov",3],olympic["Karpov",4],olympic["Karpov",5],olympic["Karpov",6],olympic["Karpov",7],olympic["Karpov",8],olympic["Karpov",9])
colnames(Karpov)=c("race100m", "longjump", "shotput", "highjump", "race400m", "race110mhurdle", "discus", "polevault","javeline")
KarpovP <- predict(linearModcombination, newdata=Karpov, interval="prediction")
KarpovC <- predict(linearModcombination, newdata=Karpov, interval="confidence")

olympic["Macey",]
Macey <- data.frame(olympic["Macey",1],olympic["Macey",2],olympic["Macey",3],olympic["Macey",4],olympic["Macey",5],olympic["Macey",6],olympic["Macey",7],olympic["Macey",8],olympic["Macey",9])
colnames(Macey)=c("race100m", "longjump", "shotput", "highjump", "race400m", "race110mhurdle", "discus", "polevault","javeline")
MaceyP <- predict(linearModcombination, newdata=Macey, interval="prediction")
MaceyC <- predict(linearModcombination, newdata=Macey, interval="confidence")

olympic["Warners",]
Warners <- data.frame(olympic["Warners",1],olympic["Warners",2],olympic["Warners",3],olympic["Warners",4],olympic["Warners",5],olympic["Warners",6],olympic["Warners",7],olympic["Warners",8],olympic["Warners",9])
colnames(Warners)=c("race100m", "longjump", "shotput", "highjump", "race400m", "race110mhurdle", "discus", "polevault","javeline")
WarnersP <- predict(linearModcombination, newdata=Warners, interval="prediction")
WarnersC <- predict(linearModcombination, newdata=Warners, interval="confidence")

olympic["Zsivoczky",]
Zsivoczky <- data.frame(olympic["Zsivoczky",1],olympic["Zsivoczky",2],olympic["Zsivoczky",3],olympic["Zsivoczky",4],olympic["Zsivoczky",5],olympic["Zsivoczky",6],olympic["Zsivoczky",7],olympic["Zsivoczky",8],olympic["Zsivoczky",9])
colnames(Zsivoczky)=c("race100m", "longjump", "shotput", "highjump", "race400m", "race110mhurdle", "discus", "polevault","javeline")
ZsivoczkyP <- predict(linearModcombination, newdata=Zsivoczky, interval="prediction")
ZsivoczkyC <- predict(linearModcombination, newdata=Zsivoczky, interval="confidence")

olympic["Hernu",]
Hernu <- data.frame(olympic["Hernu",1],olympic["Hernu",2],olympic["Hernu",3],olympic["Hernu",4],olympic["Hernu",5],olympic["Hernu",6],olympic["Hernu",7],olympic["Hernu",8],olympic["Hernu",9])
colnames(Hernu)=c("race100m", "longjump", "shotput", "highjump", "race400m", "race110mhurdle", "discus", "polevault","javeline")
HernuP <- predict(linearModcombination, newdata=Hernu, interval="prediction")
HernuC <- predict(linearModcombination, newdata=Hernu, interval="confidence")

olympic["Nool",]
Nool <- data.frame(olympic["Nool",1],olympic["Nool",2],olympic["Nool",3],olympic["Nool",4],olympic["Nool",5],olympic["Nool",6],olympic["Nool",7],olympic["Nool",8],olympic["Nool",9])
colnames(Nool)=c("race100m", "longjump", "shotput", "highjump", "race400m", "race110mhurdle", "discus", "polevault","javeline")
NoolP <- predict(linearModcombination, newdata=Nool, interval="prediction")
NoolC <- predict(linearModcombination, newdata=Nool, interval="confidence")

olympic["Bernard",]
Bernard <- data.frame(olympic["Bernard",1],olympic["Bernard",2],olympic["Bernard",3],olympic["Bernard",4],olympic["Bernard",5],olympic["Bernard",6],olympic["Bernard",7],olympic["Bernard",8],olympic["Bernard",9])
colnames(Bernard)=c("race100m", "longjump", "shotput", "highjump", "race400m", "race110mhurdle", "discus", "polevault","javeline")
BernardP <- predict(linearModcombination, newdata=Bernard, interval="prediction")
BernardC <- predict(linearModcombination, newdata=Bernard, interval="confidence")

olympic["Schwarzl",]
Schwarzl <- data.frame(olympic["Schwarzl",1],olympic["Schwarzl",2],olympic["Schwarzl",3],olympic["Schwarzl",4],olympic["Schwarzl",5],olympic["Schwarzl",6],olympic["Schwarzl",7],olympic["Schwarzl",8],olympic["Schwarzl",9])
colnames(Schwarzl)=c("race100m", "longjump", "shotput", "highjump", "race400m", "race110mhurdle", "discus", "polevault","javeline")
SchwarzlP <- predict(linearModcombination, newdata=Schwarzl, interval="prediction")
SchwarzlC <- predict(linearModcombination, newdata=Schwarzl, interval="confidence")

SebrleP
ClayP
KarpovP
MaceyP
WarnersP
ZsivoczkyP
HernuP
NoolP
BernardP
SchwarzlP

SebrleC
ClayC
KarpovC
MaceyC
WarnersC
ZsivoczkyC
HernuC
NoolC
BernardC
SchwarzlC

olympic["Sebrle",10]
olympic["Clay",10]
olympic["Karpov",10]
olympic["Macey",10]
olympic["Warners",10]
olympic["Zsivoczky",10]
olympic["Hernu",10]
olympic["Nool",10]
olympic["Bernard",10]
olympic["Schwarzl",10]
```

##################################################################################################################################
##################################################################################################################################
##################################################################################################################################
##################################################################################################################################

Q4: WORKING WITH REAL DATA

Now we are going to continue in athletics, but now the dataset is going to be a little bigger. We will use the last year Boston Marathon results, see https://www.kaggle.com/rojour/boston-results.
  
    
OBJECTIVE  
  
We want to predict the expected result for someone once we have the 10K partial, (on the same race). To do so you must specify what will be your target group, as an example you must select a woman of 20-30 years, that are involved regularly on athletics and, from this, select a subset of the dataset to be used on the analysis. Is this group different of the other possible groups?
  
You can use a PCE to start to see the relations between all the elements. 
  
  
PROCEDURE

First, we upload the data, eliminating runners with missing data, and we select the columns with the name, age, gender and times. We will then split the data into 5 clusters using Weka with K-means algorithm. Given that we want to predict the results for a woman of 20-30 years, the selected cluster is number 4. The number of cluster assigned to each runner is included in the file run.txt. As you can see in the file, cluster number 4 is the closest one to our target. Additionally, data will split into two groups to model with the first group and then test it with the second one. 

Then, we will apply PCA analysis for the model without standardizing it because it is all measured in seconds. PCA eigenvalues of the variables represents how much does the component affect the variance of the data. One way to decide how many components do we have to use to continue with our experiment is to select those which affect most the variance, so we will use the two first ones.

For the first dimension all variables influence the variance almost equally. However, for the second dimension the ones that affect the most are 5k, 10k and 35k. These same conclusions can be drawn from the following table $contrib.

Therefore we can conclude that a good combination for creating our regression model is one with all the variables.

Therefore we can conclude that a good combination for creating our regression model is one with 5k and 10k.

However, if we only use the variables with higher participation in the second dimension (5k and 10k) we get a similar adjusted R^2. We will use the model with all other values. We have to check that linear model's assumptions are met.

For academic purposes, although the assumptions are not met, we will assume that they are and we will proceed with our analysis.




RESULTS

Runner      | Real value    | Prediction Interval(PI) | Confidence Interval(CI) | Within PI | Within CI
------------| --------------|-------------------------|-------------------------|-----------|----------
r1          | 13188         | [13196.74,13537.46]     | [13351.21,13382.99]     | **F**     | **F**
r2          | 13160         | [12838.91,13178.64]     | [12999.65,13017.9]      | T         | **F**    
r3          | 13185         | [12970.08,13310.82]     | [13124.47,13156.43]     | T         | T
r4          | 13178         | [12996.5,13336.3]       | [13156.6,13176.2]       | T         | **F**
r5          | 13172         | [13016.58,13356.94]     | [13172.94,13200.58]     | T         | **F**
r6          | 13138         | [12982.53,13325.2]      | [13129.68,13178.05]     | T         | T      
r7          | 13169         | [12984.81,13324.87]     | [13143.05,13166.63]     | T         | **F**
r8          | 13129         | [12970.48,13310.26]     | [13130.8,13149.94]      | T         | **F**
r9          | 13221         | [13110.79,13450.94]     | [13268.42,13293.3]      | T         | **F**
r10         | 13152         | [12989.54,13329.37]     | [13149.47,13169.45]     | T         | T


Is the prediction accurate enough?

As before stated, prediction is not accurate, despite this, we can see that prediction falls in the prediction interval for most cases and inside confidence interval for some other cases.

On the one hand, with prediction interval we get 9/10 good predictions. On the other hand, we only get 3/10 good predictions. With these results we can conclude that with our model we can predict how well a woman of 20-30 years would do in a sigle event, for instance the next race. But it will fail with an extended interval of time, for instance the results for the races of the following year. 
Nevertheless, we have to remember that our model did not pass the assumptions test thus we can not trust it.
CODE

```{r}
require(FactoMineR)
marathon=read.table("run.txt", header=TRUE, fill=TRUE)
marathon <- na.omit(marathon)
subset=subset(marathon, cluster=="4")

len=length(subset[,1])
middle=len/2
model=subset[1:middle,]
middle2=middle+1
test=subset[middle2:len,]

myvars <- c("X5K",  "X10K", "X15K", "X20K", "Half", "X25K", "X30K", "X35K", "X40K")
model <- model[myvars]
test <- test[myvars]

model <- data.frame(lapply(model, as.character), stringsAsFactors=FALSE)

model_seconds=model
for(i in colnames(model)){
    for (j in rownames(model)){ 
        num= sapply(strsplit(model[j,i],":"),
                  function(x) {
                      x <- as.numeric(x)
                      model_seconds[j,i]<<-x[1]*3600+x[2]*60+x[3] 
                  }
        )
    }
    
}

test <- data.frame(lapply(test, as.character), stringsAsFactors=FALSE)
test_seconds=test
for(i in colnames(test)){
    for (j in rownames(test)){ 
        num= sapply(strsplit(test[j,i],":"),
                  function(x) {
                      x <- as.numeric(x)
                      test_seconds[j,i]<<-x[1]*3600+x[2]*60+x[3] 
                  }
        )
    }
    
}
model_seconds <- data.frame(lapply(model_seconds, as.numeric), stringsAsFactors=FALSE)
#sapply(model_seconds, class)
test_seconds <- data.frame(lapply(test_seconds, as.numeric), stringsAsFactors=FALSE)
#sapply(test_seconds, class)

pca <- PCA(model_seconds, graph = TRUE)
pca$eig
pca$var

colnames(model_seconds)=c("fk","tk","ftk","twk","h","twfk","thk","thfk","fok")
RegModel.1 <- lm(fok~fk+ftk+h+thfk+thk+tk+twfk+twk, data=model_seconds)
summary(RegModel.1)

RegModel.2 <- lm(fok~fk+tk, data=model_seconds)
summary(RegModel.2)

dwtest(RegModel.2, alternative ="two.sided")
shapiro.test(residuals(RegModel.2))
lmtest::bptest(RegModel.2)



data.frame(test_seconds[1,])
r1<-data.frame(test_seconds[1,])
colnames(r1)<-c("fk","tk","ftk","twk","h","twfk","thk","thfk")
predict(RegModel.1, newdata=r1, interval="prediction")
predict(RegModel.1, newdata=r1, interval="confidence")

data.frame(test_seconds[2,])
r2<-data.frame(test_seconds[2,])
colnames(r2)<-c("fk","tk","ftk","twk","h","twfk","thk","thfk")
predict(RegModel.1, newdata=r2, interval="prediction")
predict(RegModel.1, newdata=r2, interval="confidence")

data.frame(test_seconds[3,])
r3<-data.frame(test_seconds[3,])
colnames(r3)<-c("fk","tk","ftk","twk","h","twfk","thk","thfk")
predict(RegModel.1, newdata=r3, interval="prediction")
predict(RegModel.1, newdata=r3, interval="confidence")

data.frame(test_seconds[4,])
r4<-data.frame(test_seconds[4,])
colnames(r4)<-c("fk","tk","ftk","twk","h","twfk","thk","thfk")
predict(RegModel.1, newdata=r4, interval="prediction")
predict(RegModel.1, newdata=r4, interval="confidence")

data.frame(test_seconds[5,])
r5<-data.frame(test_seconds[5,])
colnames(r5)<-c("fk","tk","ftk","twk","h","twfk","thk","thfk")
predict(RegModel.1, newdata=r5, interval="prediction")
predict(RegModel.1, newdata=r5, interval="confidence")

data.frame(test_seconds[6,])
r6<-data.frame(test_seconds[6,])
colnames(r6)<-c("fk","tk","ftk","twk","h","twfk","thk","thfk")
predict(RegModel.1, newdata=r6, interval="prediction")
predict(RegModel.1, newdata=r6, interval="confidence")

data.frame(test_seconds[7,])
r7<-data.frame(test_seconds[7,])
colnames(r7)<-c("fk","tk","ftk","twk","h","twfk","thk","thfk")
predict(RegModel.1, newdata=r7, interval="prediction")
predict(RegModel.1, newdata=r7, interval="confidence")

data.frame(test_seconds[8,])
r8<-data.frame(test_seconds[8,])
colnames(r8)<-c("fk","tk","ftk","twk","h","twfk","thk","thfk")
predict(RegModel.1, newdata=r8, interval="prediction")
predict(RegModel.1, newdata=r8, interval="confidence")

data.frame(test_seconds[9,])
r9<-data.frame(test_seconds[9,])
colnames(r9)<-c("fk","tk","ftk","twk","h","twfk","thk","thfk")
predict(RegModel.1, newdata=r9, interval="prediction")
predict(RegModel.1, newdata=r9, interval="confidence")

data.frame(test_seconds[10,])
r10<-data.frame(test_seconds[10,])
colnames(r10)<-c("fk","tk","ftk","twk","h","twfk","thk","thfk")
predict(RegModel.1, newdata=r10, interval="prediction")
predict(RegModel.1, newdata=r10, interval="confidence")
```


















